# -*- coding: utf-8 -*-
import os, sys, subprocess, re, pandas as pd, numpy as np, matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve

# è·¯å¾„
BASE_DIR = "/Users/krt/krt files/Github/new_stat/credit_code"
ROOT_DIR = os.path.dirname(BASE_DIR)
OUT = os.path.join(ROOT_DIR, "outputs")
DATA_DIR = os.path.join(ROOT_DIR, "data")
os.makedirs(OUT, exist_ok=True)

scripts = [
    "train_logistic.py",
    "train_extratrees.py",
    "train_xgboost.py",
    "train_linear_regression.py"
]

def run_script(script):
    print(f"\nğŸš€ è¿è¡Œï¼š{script}")
    res = subprocess.run([sys.executable, os.path.join(BASE_DIR, script)],
                         capture_output=True, text=True)
    print(res.stdout)
    if res.stderr.strip():
        print("âš ï¸ é”™è¯¯ä¿¡æ¯ï¼š\n", res.stderr)
    return res.stdout

def parse_metrics(text):
    m = re.search(r"AUC=([\d\.]+).*AP=([\d\.]+).*KS=([\d\.]+)", text)
    if m:
        return {"AUC": float(m.group(1)), "AP": float(m.group(2)), "KS": float(m.group(3))}
    return {"AUC": np.nan, "AP": np.nan, "KS": np.nan}

plt.rcParams['font.sans-serif'] = ['Arial Unicode MS']
plt.rcParams['axes.unicode_minus'] = False

# è¿è¡Œå¹¶æ”¶é›†æŒ‡æ ‡
results = {}
for s in scripts:
    log = run_script(s)
    results[s.replace(".py","")] = parse_metrics(log)

# è¯»å–é¢„æµ‹æ–‡ä»¶
files = {
    "logistic":   os.path.join(OUT, "submission_logistic_regression.csv"),
    "extratrees": os.path.join(OUT, "submission_extra_trees.csv"),
    "xgboost":    os.path.join(OUT, "submission_xgboost.csv"),
    "linear":     os.path.join(OUT, "submission_linear_regression.csv")
}
dfs = {k: pd.read_csv(p) for k, p in files.items() if os.path.exists(p)}
if not dfs:
    raise RuntimeError("âŒ æ— æ¨¡å‹è¾“å‡ºï¼Œæ— æ³•èåˆã€‚")

# é€‰æ‹©AUCæœ€å¥½çš„ä¸¤ä¸ªæ¨¡å‹ï¼ˆè‹¥æ–‡ä»¶ç¼ºå¤±è‡ªåŠ¨è·³è¿‡ï¼‰
df_metrics = pd.DataFrame(results).T
top2 = df_metrics["AUC"].sort_values(ascending=False).head(2).index.tolist()
best_keys = [name.replace("train_","") for name in top2 if name.replace("train_","") in dfs]
if len(best_keys) < 2:
    best_keys = list(dfs.keys())[:2]

print(f"\nğŸ† å‚ä¸èåˆçš„ä¸¤ä¸ªæœ€ä½³æ¨¡å‹ï¼š{best_keys}")

# ID å¯¹é½
main_key = best_keys[0]
ids = dfs[main_key]["id"]
for k in best_keys:
    dfs[k] = dfs[k].set_index("id").reindex(ids).reset_index()

# æƒé‡æŒ‰ AUC è‡ªé€‚åº”
auc_map = {k: df_metrics.loc[f"train_{k}", "AUC"] if f"train_{k}" in df_metrics.index else 0 for k in best_keys}
sum_auc = sum(auc_map.values())
weights = {k: (v/sum_auc if sum_auc>0 else 1/len(best_keys)) for k,v in auc_map.items()}
print("ğŸ“¦ èåˆæƒé‡ï¼š", weights)

# ç”Ÿæˆèåˆç»“æœ
ensemble_prob = np.zeros(len(ids), dtype=float)
for k in best_keys:
    ensemble_prob += dfs[k]["target"].values * weights[k]

ens_df = pd.DataFrame({"id": ids, "target": ensemble_prob})
ens_path = os.path.join(OUT, "submission_ensemble.csv")
ens_df.to_csv(ens_path, index=False)
print(f"âœ… èåˆç»“æœå·²ä¿å­˜ï¼š{ens_path}")

# è®¡ç®—èåˆæŒ‡æ ‡ï¼ˆåŸºäºè®­ç»ƒé›†å‰Nè¡Œå¯¹é½ï¼‰
train_path = os.path.join(DATA_DIR, "è®­ç»ƒæ•°æ®é›†.xlsx")
if os.path.exists(train_path):
    train = pd.read_excel(train_path, sheet_name=0)
    if "target" in train.columns:
        y_true = train["target"].astype(int).values
        y_pred = ensemble_prob[:len(y_true)]
        auc = roc_auc_score(y_true, y_pred)
        ap  = average_precision_score(y_true, y_pred)
        fpr, tpr, _ = roc_curve(y_true, y_pred)
        ks  = np.max(np.abs(tpr - fpr))
        print(f"ğŸ“Š èåˆï¼ˆTop-2ï¼‰è¯„ä¼°ï¼šAUC={auc:.4f}  AP={ap:.4f}  KS={ks:.4f}")

        plt.figure(figsize=(6,5))
        plt.plot(fpr, tpr, label=f"AUC={auc:.4f}, KS={ks:.4f}")
        plt.plot([0,1],[0,1],"--",color="gray")
        plt.xlabel("å‡é˜³æ€§ç‡ (FPR)"); plt.ylabel("çœŸé˜³æ€§ç‡ (TPR)")
        plt.title("èåˆæ¨¡å‹ ROC æ›²çº¿ï¼ˆTop-2ï¼‰"); plt.legend()
        plt.tight_layout(); plt.savefig(os.path.join(OUT,"ensemble_roc_curve.png"), dpi=220); plt.close()

        results["ensemble_top2"] = {"AUC": auc, "AP": ap, "KS": ks}

# æ±‡æ€»è¡¨ + å¯¹æ¯”å›¾
cmp_path = os.path.join(OUT, "model_comparison.csv")
pd.DataFrame(results).T.to_csv(cmp_path, index_label="æ¨¡å‹åç§°")
print(f"\nâœ… æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨å·²ä¿å­˜ï¼š{cmp_path}")

dfc = pd.read_csv(cmp_path, index_col=0)
if not dfc.empty:
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    metrics = ["AUC", "AP", "KS"]; colors = ["#409EFF","#67C23A","#E6A23C"]
    for i, m in enumerate(metrics):
        ax = axes[i]
        if m in dfc.columns:
            dfc[m].plot(kind="bar", ax=ax, color=colors[i])
            ax.set_title(f"{m} æŒ‡æ ‡å¯¹æ¯”"); ax.set_xlabel("æ¨¡å‹"); ax.set_ylabel(m)
            ax.grid(axis="y", linestyle="--", alpha=0.6)
            for idx, val in enumerate(dfc[m].values):
                if pd.notna(val): ax.text(idx, val, f"{val:.3f}", ha="center", va="bottom", fontsize=9)
    plt.suptitle("å„æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾ï¼ˆå« Top-2 èåˆï¼‰")
    plt.tight_layout(rect=[0,0,1,0.95])
    plt.savefig(os.path.join(OUT, "model_comparison_plot.png"), dpi=220)
    plt.close()
    print(f"ğŸ“ˆ æ¨¡å‹æ€§èƒ½å¯¹æ¯”å›¾å·²ä¿å­˜ï¼š{os.path.join(OUT,'model_comparison_plot.png')}")
else:
    print("âš ï¸ æ— å¯¹æ¯”æ•°æ®ï¼Œæœªç»˜å›¾ã€‚")

print("\nğŸ¯ å…¨æµç¨‹å®Œæˆã€‚è¾“å‡ºç›®å½•ï¼š", OUT)
