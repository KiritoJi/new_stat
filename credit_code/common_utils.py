# -*- coding: utf-8 -*-
"""
run_all.py
-----------
æ‰§è¡Œå…¨æµç¨‹å»ºæ¨¡ï¼š
1ï¸âƒ£ é¡ºåºè¿è¡Œå››ä¸ªæ¨¡å‹è„šæœ¬
2ï¸âƒ£ è‡ªåŠ¨æå–AUC/AP/KS
3ï¸âƒ£ èåˆå‰2ä¸ªæœ€ä¼˜æ¨¡å‹
4ï¸âƒ£ æ±‡æ€»ç‰¹å¾é‡è¦æ€§å¹¶ç»˜åˆ¶Top10å›¾
5ï¸âƒ£ è¾“å‡ºä¸­æ–‡æ€§èƒ½æ€»ç»“æŠ¥å‘Š
"""

import os, sys, subprocess, re, pandas as pd, numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_auc_score, average_precision_score, roc_curve

# ===============================
# è·¯å¾„é…ç½®
# ===============================
BASE_DIR = "/Users/krt/krt files/Github/new_stat/credit_code"
ROOT_DIR = os.path.dirname(BASE_DIR)
OUT_DIR = os.path.join(ROOT_DIR, "outputs")
DATA_DIR = os.path.join(ROOT_DIR, "data")
os.makedirs(OUT_DIR, exist_ok=True)

scripts = [
    "train_logistic.py",
    "train_extratrees.py",
    "train_xgboost.py",
    "train_linear_regression.py"
]

# ===============================
# å·¥å…·å‡½æ•°
# ===============================
def run_script(name):
    """è¿è¡Œå­æ¨¡å‹è„šæœ¬"""
    print(f"\n=== ğŸš€ æ­£åœ¨è¿è¡Œæ¨¡å‹: {name} ===")
    res = subprocess.run([sys.executable, os.path.join(BASE_DIR, name)],
                         capture_output=True, text=True)
    print(res.stdout)
    if res.stderr:
        print("âš ï¸ é”™è¯¯ä¿¡æ¯:\n", res.stderr)
    return res.stdout


def parse_metrics(txt):
    """è§£æ AUC/AP/KS æŒ‡æ ‡"""
    m = re.search(r"AUC=([\d\.]+).*AP=([\d\.]+).*KS=([\d\.]+)", txt)
    if m:
        return {"AUC": float(m.group(1)), "AP": float(m.group(2)), "KS": float(m.group(3))}
    return {"AUC": np.nan, "AP": np.nan, "KS": np.nan}


# ===============================
# Step 1ï¸âƒ£ è¿è¡Œå››ä¸ªæ¨¡å‹
# ===============================
results = {}
for s in scripts:
    out = run_script(s)
    results[s.replace(".py", "")] = parse_metrics(out)

# ===============================
# Step 2ï¸âƒ£ é€‰å‡ºè¡¨ç°æœ€å¥½çš„ä¸¤ä¸ªæ¨¡å‹
# ===============================
best = sorted(results.items(), key=lambda kv: kv[1]["AUC"], reverse=True)[:2]
weights = {best[0][0]: 0.6, best[1][0]: 0.4}
print(f"\nğŸ§© èåˆæ¨¡å‹ï¼ˆTop2ï¼‰ï¼š{weights}")

# === ä¿®æ­£æ–‡ä»¶åä¸Keyæ˜ å°„ ===
dfs = {}
for name, _ in best:
    if "logistic" in name:
        file_name, key = "submission_logistic_regression.csv", "logistic"
    elif "extratrees" in name:
        file_name, key = "submission_extra_trees.csv", "extratrees"
    elif "xgboost" in name:
        file_name, key = "submission_xgboost.csv", "xgboost"
    elif "linear" in name:
        file_name, key = "submission_linear_regression.csv", "linear"
    else:
        continue
    path = os.path.join(OUT_DIR, file_name)
    if os.path.exists(path):
        dfs[key] = pd.read_csv(path)

# === æ„é€ æƒé‡æ˜ å°„ ===
mapped_weights = {}
for k, w in weights.items():
    if "logistic" in k:
        mapped_weights["logistic"] = w
    elif "extratrees" in k:
        mapped_weights["extratrees"] = w
    elif "xgboost" in k:
        mapped_weights["xgboost"] = w
    elif "linear" in k:
        mapped_weights["linear"] = w

# === åŠ æƒèåˆ ===
ids = dfs[list(dfs.keys())[0]]["id"]
# âœ… ä½¿ç”¨æ˜ å°„åçš„ keyï¼Œè€Œä¸æ˜¯åŸå§‹ weights
prob = sum(dfs[k]["target"] * w for k, w in mapped_weights.items())
ensemble_path = os.path.join(OUT_DIR, "submission_ensemble.csv")
pd.DataFrame({"id": ids, "target": prob}).to_csv(ensemble_path, index=False)
print(f"âœ… å·²ä¿å­˜èåˆç»“æœ: {ensemble_path}")

# ===============================
# Step 3ï¸âƒ£ è®¡ç®—èåˆæ¨¡å‹æŒ‡æ ‡
# ===============================
train = pd.read_excel(os.path.join(DATA_DIR, "è®­ç»ƒæ•°æ®é›†.xlsx"))
y_true = train["target"].astype(int)
auc = roc_auc_score(y_true[:len(prob)], prob[:len(y_true)])
ap = average_precision_score(y_true[:len(prob)], prob[:len(y_true)])
fpr, tpr, _ = roc_curve(y_true[:len(prob)], prob[:len(y_true)])
ks = np.max(np.abs(tpr - fpr))
print(f"\nâœ… Ensemble: AUC={auc:.4f}  AP={ap:.4f}  KS={ks:.4f}")

# ===============================
# Step 4ï¸âƒ£ æ±‡æ€»ç‰¹å¾é‡è¦æ€§
# ===============================
imp_files = [f for f in os.listdir(OUT_DIR) if f.startswith("feature_importance_")]
if imp_files:
    dfs_imp = []
    for f in imp_files:
        df = pd.read_csv(os.path.join(OUT_DIR, f))
        model = f.replace("feature_importance_", "").replace(".csv", "")
        df["model"] = model
        dfs_imp.append(df)
    imp_all = pd.concat(dfs_imp)
    mean_imp = imp_all.groupby("feature")["importance"].mean().sort_values(ascending=False).reset_index()
    mean_imp.to_csv(os.path.join(OUT_DIR, "feature_importance_overall.csv"), index=False)
    print("\nğŸ“Š å‰10ä¸ªå¹³å‡ç‰¹å¾é‡è¦æ€§ï¼š")
    print(mean_imp.head(10).to_string(index=False))

    # === ç»˜åˆ¶Top10ç‰¹å¾æ¡å½¢å›¾ ===
    top10 = mean_imp.head(10)
    plt.figure(figsize=(8, 5))
    plt.barh(top10["feature"][::-1], top10["importance"][::-1], color="steelblue")
    plt.xlabel("å¹³å‡é‡è¦æ€§")
    plt.ylabel("ç‰¹å¾å")
    plt.title("ç‰¹å¾é‡è¦æ€§ Top 10ï¼ˆå…¨æ¨¡å‹å¹³å‡ï¼‰")
    plt.tight_layout()
    plt.savefig(os.path.join(OUT_DIR, "feature_importance_top10.png"), dpi=200)
    plt.close()
    print("ğŸ“ˆ å·²ç”Ÿæˆå›¾åƒ: feature_importance_top10.png")

# ===============================
# Step 5ï¸âƒ£ æ±‡æ€»æ€§èƒ½å¯¹æ¯”è¡¨
# ===============================
df = pd.DataFrame(results).T
df.to_csv(os.path.join(OUT_DIR, "model_comparison.csv"))
print("\nâœ… æ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨å·²ä¿å­˜: model_comparison.csv")
print(df.round(4))

# ===============================
# Step 6ï¸âƒ£ ä¸­æ–‡æ€§èƒ½æ€»ç»“æŠ¥å‘Š
# ===============================
best_model_name = best[0][0].replace("train_", "")
second_model_name = best[1][0].replace("train_", "")
best_auc = results[best[0][0]]["AUC"]
second_auc = results[best[1][0]]["AUC"]
improve = (auc - best_auc) / best_auc * 100 if best_auc > 0 else 0

print("\n===============================")
print("ğŸ“‹ ä¸­æ–‡æ€§èƒ½æ€»ç»“æŠ¥å‘Š")
print("===============================")
print(f"æœ€ä¼˜å•æ¨¡å‹ï¼š{best_model_name}  (AUC={best_auc:.4f})")
print(f"æ¬¡ä¼˜æ¨¡å‹ï¼š{second_model_name}  (AUC={second_auc:.4f})")
print(f"èåˆæ¨¡å‹AUCï¼š{auc:.4f}ï¼Œè¾ƒæœ€ä¼˜å•æ¨¡å‹æå‡çº¦ {improve:.2f}%")
print(f"å¹³å‡ç²¾ç¡®ç‡(AP)ï¼š{ap:.4f}ï¼ŒKSå€¼ï¼š{ks:.4f}")
print("ç‰¹å¾é‡è¦æ€§æ–‡ä»¶ï¼šfeature_importance_overall.csv")
print("Top10ç‰¹å¾å›¾ï¼šfeature_importance_top10.png")
print("å…¨éƒ¨ç»“æœå·²è¾“å‡ºè‡³ outputs/ æ–‡ä»¶å¤¹ä¸­ âœ…")
